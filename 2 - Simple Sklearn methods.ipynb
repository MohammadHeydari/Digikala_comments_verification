{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO 2nd\n",
    "# Sklearn Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis pkg\n",
    "import pandas as pd\n",
    "\n",
    "# Feature extraction and splitting pkg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from hazm import word_tokenize, stopwords_list\n",
    "\n",
    "# For defining models and metrics pkg\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import (LogisticRegression, RidgeClassifier, SGDClassifier)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import (accuracy_score, recall_score, confusion_matrix, f1_score, \n",
    "                             roc_auc_score, classification_report)\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Avoiding warnings\n",
    "import warnings\n",
    "import os\n",
    "########### Prevent Warnings ###########\n",
    "warnings.filterwarnings(action='ignore')\n",
    "########### Prevent Warnings ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cleaned/data.csv')\n",
    "df.title = df.title.astype('str')\n",
    "df.text = df.text.astype('str')\n",
    "df.comment = df.comment.astype('str')\n",
    "df.rate = df.rate.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['text']\n",
    "label = ['verification_status']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df[features], df[label], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [text for text in X_train.text]\n",
    "Y_train = [label for label in Y_train.verification_status]\n",
    "\n",
    "X_test = [text for text in X_test.text]\n",
    "Y_test = [label for label in Y_test.verification_status]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(use_idf=True, max_features=20000,tokenizer=word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125369, 20000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer(use_idf=True, max_features=20000,tokenizer=word_tokenize)), \n",
    "    ('XGB', XGBClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "NB = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer(use_idf=True, max_features=20000,tokenizer=word_tokenize)), \n",
    "    ('NB', BernoulliNB())\n",
    "])\n",
    "\n",
    "DT = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer(use_idf=True, max_features=20000,tokenizer=word_tokenize)), \n",
    "    ('DT', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "RF = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer(use_idf=True, max_features=20000,tokenizer=word_tokenize)), \n",
    "    ('RF', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "SGD = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer(use_idf=True, max_features=20000,tokenizer=word_tokenize)), \n",
    "    ('SGD', SGDClassifier())\n",
    "])\n",
    "\n",
    "LR = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer(use_idf=True, max_features=20000,tokenizer=word_tokenize)), \n",
    "    ('LR', LogisticRegression())\n",
    "])\n",
    "\n",
    "GD = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer(use_idf=True, max_features=20000,tokenizer=word_tokenize)), \n",
    "    ('GD', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "DM = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer(use_idf=True, max_features=20000,tokenizer=word_tokenize)), \n",
    "    ('Dummy', DummyClassifier())\n",
    "])\n",
    "\n",
    "tfidf_clfs = [GD, LR, SGD, NB, XGB, RF, DT]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- tfidf:  GD : accuracy 0.8766983063465476\n",
      "- tfidf:  GD : RECALL  0.8543956043956044\n",
      "- tfidf:  GD : F1_SCORE 0.45798903706127786\n",
      "- tfidf:  GD : ROC 0.8662710174037324\n",
      "\n",
      "-------------\n",
      "- tfidf:  LR : accuracy 0.8976363297971338\n",
      "- tfidf:  LR : RECALL  0.8315060588574726\n",
      "- tfidf:  LR : F1_SCORE 0.6111975116640747\n",
      "- tfidf:  LR : ROC 0.8681133764234408\n",
      "\n",
      "-------------\n",
      "- tfidf:  SGD : accuracy 0.8810534152242695\n",
      "- tfidf:  SGD : RECALL  0.8776595744680851\n",
      "- tfidf:  SGD : F1_SCORE 0.48171275646743983\n",
      "- tfidf:  SGD : ROC 0.8794705531340148\n",
      "\n",
      "-------------\n",
      "- tfidf:  NB : accuracy 0.8805509026614554\n",
      "- tfidf:  NB : RECALL  0.7381804482953476\n",
      "- tfidf:  NB : F1_SCORE 0.5498035914702581\n",
      "- tfidf:  NB : ROC 0.8171706024959111\n",
      "\n",
      "-------------\n",
      "- tfidf:  XGB : accuracy 0.8742043551088777\n",
      "- tfidf:  XGB : RECALL  0.8605800922874094\n",
      "- tfidf:  XGB : F1_SCORE 0.43585677322427174\n",
      "- tfidf:  XGB : ROC 0.8677999088547667\n",
      "\n",
      "-------------\n",
      "- tfidf:  RF : accuracy 0.8836962590731435\n",
      "- tfidf:  RF : RECALL  0.8235011990407674\n",
      "- tfidf:  RF : F1_SCORE 0.5235953342990013\n",
      "- tfidf:  RF : ROC 0.8561311483500849\n",
      "\n",
      "-------------\n",
      "- tfidf:  DT : accuracy 0.8495440163781872\n",
      "- tfidf:  DT : RECALL  0.5550031867431485\n",
      "- tfidf:  DT : F1_SCORE 0.518580276322058\n",
      "- tfidf:  DT : ROC 0.7274525577390146\n",
      "\n",
      "-------------\n",
      "- tfidf:  Dummy : accuracy 0.7205657919225759\n",
      "- tfidf:  Dummy : RECALL  0.16132633694317294\n",
      "- tfidf:  Dummy : F1_SCORE 0.16141644325290438\n"
     ]
    }
   ],
   "source": [
    "for clf in tfidf_clfs:\n",
    "    clf.fit(X_train, Y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    print('- tfidf: ', clf.steps[1][0], ': accuracy' , accuracy_score(preds, Y_test))\n",
    "    print('- tfidf: ', clf.steps[1][0], ': RECALL ' , recall_score(preds, Y_test))\n",
    "    print('- tfidf: ', clf.steps[1][0], ': F1_SCORE' , f1_score(preds, Y_test))\n",
    "    print('')\n",
    "    print('-------------')\n",
    "    \n",
    "DM.fit(X_train, Y_train)\n",
    "preds = DM.predict(X_test)\n",
    "print('- tfidf: ', DM.steps[1][0], ': accuracy' , accuracy_score(preds, Y_test))\n",
    "print('- tfidf: ', DM.steps[1][0], ': RECALL ' , recall_score(preds, Y_test))\n",
    "print('- tfidf: ', DM.steps[1][0], ': F1_SCORE' , f1_score(preds, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = Pipeline([\n",
    "    ('countvect',CountVectorizer(max_features=20000, tokenizer=word_tokenize, stop_words=stopwords_list())), \n",
    "    ('XGB', XGBClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "NB = Pipeline([\n",
    "    ('countvect',CountVectorizer(max_features=20000, tokenizer=word_tokenize, stop_words=stopwords_list())), \n",
    "    ('NB', BernoulliNB())\n",
    "])\n",
    "\n",
    "DT = Pipeline([\n",
    "    ('countvect',CountVectorizer(max_features=20000, tokenizer=word_tokenize, stop_words=stopwords_list())), \n",
    "    ('DT', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "RF = Pipeline([\n",
    "    ('countvect',CountVectorizer(max_features=20000, tokenizer=word_tokenize, stop_words=stopwords_list())), \n",
    "    ('RF', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "SGD = Pipeline([\n",
    "    ('countvect',CountVectorizer(max_features=20000, tokenizer=word_tokenize, stop_words=stopwords_list())), \n",
    "    ('SGD', SGDClassifier())\n",
    "])\n",
    "\n",
    "LR = Pipeline([\n",
    "    ('countvect', CountVectorizer(max_features=20000, tokenizer=word_tokenize, stop_words=stopwords_list())), \n",
    "    ('LR', LogisticRegression())\n",
    "])\n",
    "\n",
    "GD = Pipeline([\n",
    "    ('countvect', CountVectorizer(max_features=20000, tokenizer=word_tokenize, stop_words=stopwords_list())), \n",
    "    ('GD', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "DM = Pipeline([\n",
    "    ('countvect', CountVectorizer(max_features=20000, tokenizer=word_tokenize, stop_words=stopwords_list())), \n",
    "    ('Dummy', DummyClassifier())\n",
    "])\n",
    "\n",
    "countvect_clfs = [GD, LR, SGD, NB, XGB, RF, DT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- countvect:  GD : accuracy 0.8742229666852782\n",
      "- countvect:  GD : RECALL  0.8283828382838284\n",
      "- countvect:  GD : F1_SCORE 0.4496742671009773\n",
      "- countvect:  GD : ROC 0.8528187183859169\n",
      "- countvect:  LR : accuracy 0.8914200632793597\n",
      "- countvect:  LR : RECALL  0.7673939185706923\n",
      "- countvect:  LR : F1_SCORE 0.6049566630552545\n",
      "- countvect:  LR : ROC 0.8369416523492799\n",
      "- countvect:  SGD : accuracy 0.8916620137725665\n",
      "- countvect:  SGD : RECALL  0.8040856031128405\n",
      "- countvect:  SGD : F1_SCORE 0.5867821395612975\n",
      "- countvect:  SGD : ROC 0.852505859798857\n",
      "- countvect:  NB : accuracy 0.8805509026614554\n",
      "- countvect:  NB : RECALL  0.7381804482953476\n",
      "- countvect:  NB : F1_SCORE 0.5498035914702581\n",
      "- countvect:  NB : ROC 0.8171706024959111\n",
      "- countvect:  XGB : accuracy 0.8726968174204355\n",
      "- countvect:  XGB : RECALL  0.8354027379815345\n",
      "- countvect:  XGB : F1_SCORE 0.4341495698213105\n",
      "- countvect:  XGB : ROC 0.8552075462229719\n",
      "- countvect:  RF : accuracy 0.879322538619021\n",
      "- countvect:  RF : RECALL  0.7739710789766407\n",
      "- countvect:  RF : F1_SCORE 0.5176313048653475\n",
      "- countvect:  RF : ROC 0.8314559365635716\n",
      "- countvect:  DT : accuracy 0.8446491717848502\n",
      "- countvect:  DT : RECALL  0.5366658518699584\n",
      "- countvect:  DT : F1_SCORE 0.5126977640259209\n",
      "- countvect:  DT : ROC 0.7183197530184955\n",
      "- tfidf:  DT : accuracy 0.7221849990694211\n",
      "- tfidf:  DT : RECALL  0.16770393420760168\n",
      "- tfidf:  DT : F1_SCORE 0.16818055168570634\n"
     ]
    }
   ],
   "source": [
    "for clf in countvect_clfs:\n",
    "    clf.fit(X_train, Y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    print('- countvect: ', clf.steps[1][0], ': accuracy' , accuracy_score(preds, Y_test))\n",
    "    print('- countvect: ', clf.steps[1][0], ': RECALL ' , recall_score(preds, Y_test))\n",
    "    print('- countvect: ', clf.steps[1][0], ': F1_SCORE' , f1_score(preds, Y_test))\n",
    "    print('')\n",
    "    \n",
    "DM.fit(X_train, Y_train)\n",
    "preds = DM.predict(X_test)\n",
    "print('- tfidf: ', clf.steps[1][0], ': accuracy' , accuracy_score(preds, Y_test))\n",
    "print('- tfidf: ', clf.steps[1][0], ': RECALL ' , recall_score(preds, Y_test))\n",
    "print('- tfidf: ', clf.steps[1][0], ': F1_SCORE' , f1_score(preds, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEST RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec - > max_featres = 500000 words\n",
    "\n",
    "TF-IDF vectorizer = tokenizer=word_tokenize, stop_words=stopwords_list()\n",
    "\n",
    "- XGBoost  ROC with TF-IDF 0.8698764600833205\n",
    "- XGBoost  RECALL with TF-IDF 0.8632228719948019\n",
    "- XGBoost  F1_SCORE with TF-IDF 0.44323963633330554\n",
    "- XGBoost  ROC with CountVectorizer 0.8632321810604328\n",
    "- XGBoost  RECALL with TF-IDF 0.850452196382429\n",
    "- XGBoost  F1_SCORE with TF-IDF 0.4385774964603982\n",
    "\n",
    "\n",
    "- DecissionTree  ROC with TF-IDF 0.7331272294078325\n",
    "- DecissionTree  RECALL with TF-IDF 0.563496078927397\n",
    "- DecissionTree  F1_SCORE with TF-IDF 0.5298210144496641\n",
    "- DecissionTree  ROC with CountVectorizer 0.7190879149589758\n",
    "- DecissionTree  RECALL with TF-IDF 0.5359281437125748\n",
    "- DecissionTree  F1_SCORE with TF-IDF 0.5185099356931812\n",
    "\n",
    "\n",
    "- RandomForest  ROC with TF-IDF 0.8548763832596875\n",
    "- RandomForest  RECALL with TF-IDF 0.8246113989637306\n",
    "- RandomForest  F1_SCORE with TF-IDF 0.49847310312426585\n",
    "- RandomForest  ROC with CountVectorizer 0.8348634819172763\n",
    "- RandomForest  RECALL with TF-IDF 0.7804933242815116\n",
    "- RandomForest  F1_SCORE with TF-IDF 0.5174793698424607\n",
    "\n",
    "\n",
    "\n",
    "- StochasticGD  ROC with TF-IDF 0.8841407191082541\n",
    "- StochasticGD  RECALL with TF-IDF 0.8857988165680474\n",
    "- StochasticGD  F1_SCORE with TF-IDF 0.4871857456675617\n",
    "- StochasticGD  ROC with CountVectorizer 0.8633177818641357\n",
    "- StochasticGD  RECALL with TF-IDF 0.8245125348189415\n",
    "- StochasticGD  F1_SCORE with TF-IDF 0.5946760421898544\n",
    "\n",
    "\n",
    "- LogisticRegression  ROC with TF-IDF 0.8720273079056319\n",
    "- LogisticRegression  RECALL with TF-IDF 0.8391389432485323\n",
    "- LogisticRegression  F1_SCORE with TF-IDF 0.6116539476499536\n",
    "- LogisticRegression  ROC with CountVectorizer 0.8398848822483052\n",
    "- LogisticRegression  RECALL with TF-IDF 0.7724913494809689\n",
    "- LogisticRegression  F1_SCORE with TF-IDF 0.6078551494112041\n",
    "\n",
    "\n",
    "- Gradient Descent_ensembele  ROC with TF-IDF 0.8672471652995906\n",
    "- Gradient Descent_ensembele  RECALL with TF-IDF 0.8555725190839695\n",
    "- Gradient Descent_ensembele  F1_SCORE with TF-IDF 0.45987198424421466\n",
    "- Gradient Descent_ensembele  ROC with CountVectorizer 0.8586466391934725\n",
    "- Gradient Descent_ensembele  RECALL with TF-IDF 0.8386322735452909\n",
    "- Gradient Descent_ensembele  F1_SCORE with TF-IDF 0.4566761943650469\n",
    "\n",
    "\n",
    "\n",
    "- BernouliNB  ROC with TF-IDF 0.8250477680396926\n",
    "- BernouliNB  RECALL with TF-IDF 0.7519863791146425\n",
    "- BernouliNB  F1_SCORE with TF-IDF 0.5599774600267663\n",
    "- BernouliNB  ROC with CountVectorizer 0.8250477680396926\n",
    "- BernouliNB  RECALL with TF-IDF 0.7519863791146425\n",
    "- BernouliNB  F1_SCORE with TF-IDF 0.5599774600267663\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
